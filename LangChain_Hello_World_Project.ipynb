{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjXPYTgkSyJHxZ9PMIkLW/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5jzQEw2dzpw"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n"
      ],
      "metadata": {
        "id": "YWRg6-e6fBfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key= userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "qDMci2gQfL-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    api_key=api_key,\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0.3 ,max_tokens=200\n",
        ")\n"
      ],
      "metadata": {
        "id": "LXiB69xIk9K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"history\", \"question\"],\n",
        "template=\"You are a helpful assistant . Answer the following question :\\n\\n{question}\"\n",
        ")"
      ],
      "metadata": {
        "id": "_cNmNDq9fmp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory()"
      ],
      "metadata": {
        "id": "ENSE2a4Zf0lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt_template, memory=memory)"
      ],
      "metadata": {
        "id": "A_tWwBJhf321"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input_history = []\n",
        "\n",
        "while True:\n",
        "    question = input(\"How can I help you? : \")\n",
        "    user_input = question\n",
        "    if user_input.lower() == \"exit\":\n",
        "        break\n",
        "    print(\"Generating response...\")\n",
        "    response = chain.invoke({\"question\": question})\n",
        "    print(response['text'])\n",
        "    user_input_history.append({\"user\": question, \"response\": response['text']})\n",
        "\n",
        "user_input_history"
      ],
      "metadata": {
        "id": "TjxBsIzOf7QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B41jdTVDpN1t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}